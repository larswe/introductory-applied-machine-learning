{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Decision trees and linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this lab we perform Decision trees classification on the [German credit](http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) data set. In the second part we learn how to train simple linear regression model by using the [CPU performance](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware) data set. Both datasets (`credit.csv` and `cpu.csv`) are located within the `datasets` directory (adjacent to this file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, first activate the python environment if not already done so (remember to exclude 'source' if you're on windows):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bash}\n",
    "source activate py3iaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the packages (*This will generate some warnings related to the libraries: ignore*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsw\\anaconda3\\envs\\py3iaml\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "C:\\Users\\larsw\\anaconda3\\envs\\py3iaml\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Trees\n",
    "One of the great advantages of decision trees is their interpretability. The rules learnt for classification are easy for a person to follow, unlike the opaque \"black box\" of many other methods, such as neural networks. We demonstrate the utility of this using a German credit data set. You can read a description of this dataset at the [UCI site](http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29). The task is to predict whether a loan approval is good or bad credit risk based on 20 attributes. We've simplified the data set somewhat, particularly making attribute names and values more meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will load the credit dataset into a pandas DataFrame structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'credit.csv')\n",
    "credit = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Display the number of data points and attributes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(credit))\n",
    "print(len(credit.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "Get a feeling of the data by using pandas `describe()` method. Be careful - there is a mixture of numeric and categorical data and hence will need to output it in two stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>CreditAmount</th>\n",
       "      <th>InstallmentRate</th>\n",
       "      <th>ResidentSince</th>\n",
       "      <th>Age</th>\n",
       "      <th>NumCreditsAtBank</th>\n",
       "      <th>Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1.001000e+03</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.882118</td>\n",
       "      <td>-9.957330e+05</td>\n",
       "      <td>-7.019980</td>\n",
       "      <td>2.842158</td>\n",
       "      <td>35.217782</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.969031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.070878</td>\n",
       "      <td>3.160708e+07</td>\n",
       "      <td>316.165715</td>\n",
       "      <td>1.106825</td>\n",
       "      <td>15.398264</td>\n",
       "      <td>31.656714</td>\n",
       "      <td>5.894916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-293.000000</td>\n",
       "      <td>-1000.000000</td>\n",
       "      <td>-185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.364000e+03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.319000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.972000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.842400e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration  CreditAmount  InstallmentRate  ResidentSince          Age  \\\n",
       "count  1001.000000  1.001000e+03      1001.000000    1001.000000  1001.000000   \n",
       "mean     20.882118 -9.957330e+05        -7.019980       2.842158    35.217782   \n",
       "std      12.070878  3.160708e+07       316.165715       1.106825    15.398264   \n",
       "min       0.000000 -1.000000e+09    -10000.000000       0.000000  -293.000000   \n",
       "25%      12.000000  1.364000e+03         2.000000       2.000000    27.000000   \n",
       "50%      18.000000  2.319000e+03         3.000000       3.000000    33.000000   \n",
       "75%      24.000000  3.972000e+03         4.000000       4.000000    42.000000   \n",
       "max      72.000000  1.842400e+04         4.000000       4.000000    75.000000   \n",
       "\n",
       "       NumCreditsAtBank   Dependents  \n",
       "count       1001.000000  1001.000000  \n",
       "mean           0.406593     0.969031  \n",
       "std           31.656714     5.894916  \n",
       "min        -1000.000000  -185.000000  \n",
       "25%            1.000000     1.000000  \n",
       "50%            1.000000     1.000000  \n",
       "75%            2.000000     1.000000  \n",
       "max            4.000000     2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Numeric Data\n",
    "credit.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckingAccount</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>SavingsAccount</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PersonalStatus</th>\n",
       "      <th>OtherDebtors</th>\n",
       "      <th>Property</th>\n",
       "      <th>OtherPlans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Job</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>none</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>television</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>car</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>skilled</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>394</td>\n",
       "      <td>530</td>\n",
       "      <td>280</td>\n",
       "      <td>603</td>\n",
       "      <td>339</td>\n",
       "      <td>548</td>\n",
       "      <td>908</td>\n",
       "      <td>333</td>\n",
       "      <td>815</td>\n",
       "      <td>714</td>\n",
       "      <td>631</td>\n",
       "      <td>596</td>\n",
       "      <td>963</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CheckingAccount CreditHistory     Purpose SavingsAccount YearsEmployed  \\\n",
       "count             1001          1001        1001           1001          1001   \n",
       "unique               4             5          10              5             5   \n",
       "top               none    ok_til_now  television           <100            <4   \n",
       "freq               394           530         280            603           339   \n",
       "\n",
       "       PersonalStatus OtherDebtors Property OtherPlans Housing      Job  \\\n",
       "count            1001         1001     1001       1001    1001     1001   \n",
       "unique              5            3        4          3       3        4   \n",
       "top       male_single         none      car       none     own  skilled   \n",
       "freq              548          908      333        815     714      631   \n",
       "\n",
       "       Telephone Foreign Approve  \n",
       "count       1001    1001    1001  \n",
       "unique         2       2       2  \n",
       "top           no     yes    good  \n",
       "freq         596     963     701  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Categorical Data\n",
    "credit.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "Display the first 10 data points of the dataset\n",
    "\n",
    "*TIP*: You may need to set the option to display all columns: look at [pandas.set_option](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.set_option.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckingAccount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>CreditAmount</th>\n",
       "      <th>SavingsAccount</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>InstallmentRate</th>\n",
       "      <th>PersonalStatus</th>\n",
       "      <th>OtherDebtors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property</th>\n",
       "      <th>Age</th>\n",
       "      <th>OtherPlans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>NumCreditsAtBank</th>\n",
       "      <th>Job</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ok</td>\n",
       "      <td>furniture</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>-10000.0</td>\n",
       "      <td>female_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>-293.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>television</td>\n",
       "      <td>1.169000e+03</td>\n",
       "      <td>unknown</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>television</td>\n",
       "      <td>5.951000e+03</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>12.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>education</td>\n",
       "      <td>2.096000e+03</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>furniture</td>\n",
       "      <td>7.882000e+03</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>savings</td>\n",
       "      <td>45.0</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CheckingAccount  Duration CreditHistory     Purpose  CreditAmount  \\\n",
       "0              <0       0.0            ok   furniture -1.000000e+09   \n",
       "1              <0       6.0      critical  television  1.169000e+03   \n",
       "2            <200      48.0    ok_til_now  television  5.951000e+03   \n",
       "3            none      12.0      critical   education  2.096000e+03   \n",
       "4              <0      42.0    ok_til_now   furniture  7.882000e+03   \n",
       "\n",
       "  SavingsAccount YearsEmployed  InstallmentRate PersonalStatus OtherDebtors  \\\n",
       "0        unknown    unemployed         -10000.0  female_single         none   \n",
       "1        unknown           >=7              4.0    male_single         none   \n",
       "2           <100            <4              2.0         female         none   \n",
       "3           <100            <7              2.0    male_single         none   \n",
       "4           <100            <7              2.0    male_single    guarantor   \n",
       "\n",
       "    ...       Property    Age  OtherPlans Housing NumCreditsAtBank        Job  \\\n",
       "0   ...            car -293.0        none     own          -1000.0    skilled   \n",
       "1   ...    real_estate   67.0        none     own              2.0    skilled   \n",
       "2   ...    real_estate   22.0        none     own              1.0    skilled   \n",
       "3   ...    real_estate   49.0        none     own              1.0  unskilled   \n",
       "4   ...        savings   45.0        none    free              1.0    skilled   \n",
       "\n",
       "  Dependents  Telephone Foreign Approve  \n",
       "0     -185.0        yes      no    good  \n",
       "1        1.0        yes     yes    good  \n",
       "2        1.0         no     yes     bad  \n",
       "3        2.0         no     yes    good  \n",
       "4        2.0         no     yes    good  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "When presented with a dataset, it is usually a good idea to visualise it first. By using seaborn's [pairplot](https://seaborn.github.io/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) function, try visualising a scatter plot of the `Age` and `Duration` variables. You can use the `Approve` variable as the `hue` parameter to visualise results separately for each class. Do you notice anything unusual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 492.75x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(credit, hue=\"Approve\", x_vars=\"Age\", y_vars=\"Duration\", height=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly an outlier that we want to exclude. No person in a credit dataset should have an age of -300 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "In the previous point you should have found a data point, which seems to be corrupted, as some of its values are nonsensical. Even a single point like this can significantly affect the performance of a classifier. How do you think it would affect Decision trees? How about Naive Bayes? A good way to check this is to test the performance of each classifier before and after removing this datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***\n",
    "\n",
    "With Decision Trees, things aren't so bad. Having this outlier would introduce a slight bias, but chances are it wouldn't affect many splits in a decisive way.\n",
    "\n",
    "With Naive Bayes however, things would be quite bad. Trying to fit a normal distribution to the values of the Age parameter would not be easy, because for any sensible fit to the \"real\" data, the probability of the outlier occurring would be infinitesimally small. Therefore, the according Bell curve would probably shift to the left by a noticeable amount, which could affect our future classifications in a negative way.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "Now we want to remove this instance from the dataset by using a filter. In general, we want to remove all instances, where the age of an applicant is lower than 0 years, as this suggests that the instance is corrupted. Use logical indexing to get rid of these instances without creating a new dataframe. Display the number of data points after any outliers have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "credit = credit.loc[credit[\"Age\"] >= 0]\n",
    "print(len(credit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "\n",
    "You might have noticed that most of the attributes in the dataset are in fact discrete. Now we want to know which variables exactly are discrete (both categorical and numerical, look [here](http://stats.stackexchange.com/questions/206/what-is-the-difference-between-discrete-data-and-continuous-data) if you are unsure about the difference) and which are continuous variables. In order to do so, we will inspect the number of possible values that each attribute can take. \n",
    "\n",
    "Display the number of values each attributes takes in the dataset. *Hint: As a first step, you want to loop over the columns of the DataFrame. Then you might find the numpy `unique` function quite useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckingAccount 4\n",
      "Duration 33\n",
      "CreditHistory 5\n",
      "Purpose 10\n",
      "CreditAmount 921\n",
      "SavingsAccount 5\n",
      "YearsEmployed 5\n",
      "InstallmentRate 4\n",
      "PersonalStatus 4\n",
      "OtherDebtors 3\n",
      "ResidentSince 4\n",
      "Property 4\n",
      "Age 53\n",
      "OtherPlans 3\n",
      "Housing 3\n",
      "NumCreditsAtBank 4\n",
      "Job 4\n",
      "Dependents 2\n",
      "Telephone 2\n",
      "Foreign 2\n",
      "Approve 2\n"
     ]
    }
   ],
   "source": [
    "for col in credit.columns:\n",
    "    print(col, len(np.unique(credit[col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the variables `Duration`, `CreditAmount` and `Age` are continuous and all the rest are discrete. The discrete variables are not in a very convenient format though. Ideally we would want the discrete attributes to take values between `0` and `n_values-1`. Pandas has a handy way of dealing with [Categorical](https://pandas.pydata.org/pandas-docs/version/0.23.4/categorical.html) data, which you are encouraged to get familiar with.\n",
    "\n",
    "We will create a new DataFrame called `credit_clean` and convert all the discrete variables from `credit` into pandas Categorical types. Remember, we want to change the discrete variables only, so we will have to exclude the `CreditAmount`, `Age` and `Duration` attributes. Also, we don't really mind if the target variable is categorical, so we won't be transforming the `Approve` attribute either. Execute the cell below and make sure you understand what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_clean = credit.copy(deep=True) # Make a copy of the DataFrame\n",
    "for column in credit_clean.columns:   \n",
    "    if column not in ['CreditAmount', 'Age', 'Duration', 'Approve']: # Exclude non discrete columns and the target\n",
    "        credit_clean[column] = credit_clean[column].astype('category') # Convert using astype(...) method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "Display the first 10 data points of the clean data. Does it look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckingAccount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>CreditAmount</th>\n",
       "      <th>SavingsAccount</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>InstallmentRate</th>\n",
       "      <th>PersonalStatus</th>\n",
       "      <th>OtherDebtors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property</th>\n",
       "      <th>Age</th>\n",
       "      <th>OtherPlans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>NumCreditsAtBank</th>\n",
       "      <th>Job</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Approve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>television</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>television</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>12.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>education</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>furniture</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>savings</td>\n",
       "      <td>45.0</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>past_delays</td>\n",
       "      <td>car_new</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>53.0</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>36.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>education</td>\n",
       "      <td>9055.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>35.0</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>furniture</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>&lt;1000</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings</td>\n",
       "      <td>53.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>car_used</td>\n",
       "      <td>6948.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>35.0</td>\n",
       "      <td>none</td>\n",
       "      <td>rent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>management</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ok_til_now</td>\n",
       "      <td>television</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>&gt;=1000</td>\n",
       "      <td>&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male_divorced</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>61.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;200</td>\n",
       "      <td>30.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>car_new</td>\n",
       "      <td>5234.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male_married</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>28.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>management</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CheckingAccount  Duration CreditHistory     Purpose  CreditAmount  \\\n",
       "1               <0       6.0      critical  television        1169.0   \n",
       "2             <200      48.0    ok_til_now  television        5951.0   \n",
       "3             none      12.0      critical   education        2096.0   \n",
       "4               <0      42.0    ok_til_now   furniture        7882.0   \n",
       "5               <0      24.0   past_delays     car_new        4870.0   \n",
       "6             none      36.0    ok_til_now   education        9055.0   \n",
       "7             none      24.0    ok_til_now   furniture        2835.0   \n",
       "8             <200      36.0    ok_til_now    car_used        6948.0   \n",
       "9             none      12.0    ok_til_now  television        3059.0   \n",
       "10            <200      30.0      critical     car_new        5234.0   \n",
       "\n",
       "   SavingsAccount YearsEmployed InstallmentRate PersonalStatus OtherDebtors  \\\n",
       "1         unknown           >=7             4.0    male_single         none   \n",
       "2            <100            <4             2.0         female         none   \n",
       "3            <100            <7             2.0    male_single         none   \n",
       "4            <100            <7             2.0    male_single    guarantor   \n",
       "5            <100            <4             3.0    male_single         none   \n",
       "6         unknown            <4             2.0    male_single         none   \n",
       "7           <1000           >=7             3.0    male_single         none   \n",
       "8            <100            <4             2.0    male_single         none   \n",
       "9          >=1000            <7             2.0  male_divorced         none   \n",
       "10           <100    unemployed             4.0   male_married         none   \n",
       "\n",
       "     ...       Property   Age  OtherPlans Housing NumCreditsAtBank  \\\n",
       "1    ...    real_estate  67.0        none     own              2.0   \n",
       "2    ...    real_estate  22.0        none     own              1.0   \n",
       "3    ...    real_estate  49.0        none     own              1.0   \n",
       "4    ...        savings  45.0        none    free              1.0   \n",
       "5    ...        unknown  53.0        none    free              2.0   \n",
       "6    ...        unknown  35.0        none    free              1.0   \n",
       "7    ...        savings  53.0        none     own              1.0   \n",
       "8    ...            car  35.0        none    rent              1.0   \n",
       "9    ...    real_estate  61.0        none     own              1.0   \n",
       "10   ...            car  28.0        none     own              2.0   \n",
       "\n",
       "           Job Dependents Telephone Foreign Approve  \n",
       "1      skilled        1.0       yes     yes    good  \n",
       "2      skilled        1.0        no     yes     bad  \n",
       "3    unskilled        2.0        no     yes    good  \n",
       "4      skilled        2.0        no     yes    good  \n",
       "5      skilled        2.0        no     yes     bad  \n",
       "6    unskilled        2.0       yes     yes    good  \n",
       "7      skilled        1.0        no     yes    good  \n",
       "8   management        1.0       yes     yes    good  \n",
       "9    unskilled        1.0        no     yes    good  \n",
       "10  management        1.0        no     yes     bad  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.9 ==========\n",
    "\n",
    "There is a **conceptual** problem with using an (unordered) categorical input to train a decision tree. Can you figure it out? *Hint*: Look at the data-types supported by the `DecisionTreeClassifier`, specifically the input to the [fit](http://scikit-learn.org/0.19/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***\n",
    "\n",
    "Input data to the fit method is converted to float internally. The conceptual problem is then that the algorithm will assume that the categories are ordered, which will affect the judgement of the algorithm in unwanted ways. The algorithm cannot draw a boundary between 2 categorical values without drawing a line between the categories to its' \"left and right\" at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.10 ==========\n",
    "\n",
    "Let us then convert the categorical values we just created into a one-hot-encoding. Pandas provides this functionality conveniently via the [`get_dummies`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.get_dummies.html) method. Use it to generate a matrix `X` containing the one-hot encoded categorical features as well as the floating-point attributes (`CreditAmount`, `Age` and `Duration`). Also, (separately) extract the target variable (`Approve`) into a vector `y`. In each case, display the shape of the matrix/vector `X` and `y`. \n",
    "\n",
    "*TIP: It will be useful to keep track of the column names in the new one-hot-encoded format for later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 71)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = credit_clean.drop(columns=[\"Approve\"])\n",
    "X = pd.get_dummies(X)\n",
    "one_hot_cols = X.columns\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the Target y (and print its shape)\n",
    "\n",
    "# Your Code goes here:\n",
    "y = credit_clean[\"Approve\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Confirm that you have 71 input features, one target variable and 1000 data points). *Bonus Question*: where did the 71 come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out validation\n",
    "In the next step we will be using a Decision Tree classifier model. To get an accurate estimate of the model's classification performance we will use hold-out validation. Familiriase yourself with the logic behind [`train_test_split CV`](http://scikit-learn.org/0.19/modules/cross_validation.html#cross-validation-evaluating-estimator-performance) (also called `Hold-out` validation) and [how it is used](http://scikit-learn.org/0.19/modules/generated/sklearn.cross_validation.train_test_split.html) in `Scikit-learn`. Execute the cell below to create your training/testing sets by assigning 10% of the data to the test set (and convince yourself you understand what is going on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.11 ==========\n",
    "Confirm that `X_train` and `X_test` matrices are subsets of `X` by displaying the number of rows in the three matrices (no need to make use of set theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "100\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.12 ==========\n",
    "Now we will train a Decision Tree classifier on the training data. Read about [Decision Tree classifiers](http://scikit-learn.org/0.19/modules/tree.html) in `Scikit-learn` and how they are [used](http://scikit-learn.org/0.19/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). \n",
    "Create a `DecisionTreeClassifier` instance, naming it `dt` and train it by using training data only (i.e. `X_train` and `y_tain`). Set the `criterion` attribute to `entropy` in order to measure the quality of splits by using the information gain. Use the default settings for the rest of parameters. By default, trees are grown to full depth; this means that very fine splits are made involving very few data points. Not only does this make the trees hard to visualise (they'll be deep), but also we could be overfitting the data. For now, we arbitrarily choose a depth of 2 for our tree (to make it easier to interpret below), but this is a parameter we could tune. For consistency, use a `random_state=1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1000,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, random_state=1000)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have mentioned in the class that decision trees have the advantage of being interpretable by humans. Now we visualise the decision tree we have just trained. Scikit-learn can export the tree in a `.dot` format. Run the following code (replace `column_names` with whatever you used to store the names of the columns of the extended feature-space):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"560pt\" height=\"314pt\"\r\n",
       " viewBox=\"0.00 0.00 560.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 556,-310 556,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.560784\" stroke=\"black\" d=\"M370,-306C370,-306 182,-306 182,-306 176,-306 170,-300 170,-294 170,-294 170,-235 170,-235 170,-229 176,-223 182,-223 182,-223 370,-223 370,-223 376,-223 382,-229 382,-235 382,-235 382,-294 382,-294 382,-300 376,-306 370,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CheckingAccount_none &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.888</text>\r\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 900</text>\r\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [275, 625]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.250980\" stroke=\"black\" d=\"M245,-187C245,-187 139,-187 139,-187 133,-187 127,-181 127,-175 127,-175 127,-116 127,-116 127,-110 133,-104 139,-104 139,-104 245,-104 245,-104 251,-104 257,-110 257,-116 257,-116 257,-175 257,-175 257,-181 251,-187 245,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Duration &lt;= 11.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.985</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 544</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [233, 311]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.857,-222.907C240.471,-214.014 233.648,-204.509 227.058,-195.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.767,-193.103 221.092,-187.021 224.081,-197.185 229.767,-193.103\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"217.042\" y=\"-207.991\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.866667\" stroke=\"black\" d=\"M434.5,-187C434.5,-187 287.5,-187 287.5,-187 281.5,-187 275.5,-181 275.5,-175 275.5,-175 275.5,-116 275.5,-116 275.5,-110 281.5,-104 287.5,-104 287.5,-104 434.5,-104 434.5,-104 440.5,-104 446.5,-110 446.5,-116 446.5,-116 446.5,-175 446.5,-175 446.5,-181 440.5,-187 434.5,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">OtherPlans_none &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.524</text>\r\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 356</text>\r\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 314]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.49,-222.907C311.951,-214.014 318.857,-204.509 325.524,-195.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.516,-197.168 331.562,-187.021 322.853,-193.054 328.516,-197.168\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"335.473\" y=\"-208.013\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.741176\" stroke=\"black\" d=\"M104,-68C104,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 104,-0 104,-0 110,-0 116,-6 116,-12 116,-12 116,-56 116,-56 116,-62 110,-68 104,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.735</text>\r\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 92</text>\r\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [19, 73]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.103,-103.726C130.495,-94.2406 118.153,-84.1551 106.602,-74.7159\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.708,-71.9171 98.7502,-68.2996 104.279,-77.3375 108.708,-71.9171\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.101961\" stroke=\"black\" d=\"M252,-68C252,-68 146,-68 146,-68 140,-68 134,-62 134,-56 134,-56 134,-12 134,-12 134,-6 140,-0 146,-0 146,-0 252,-0 252,-0 258,-0 264,-6 264,-12 264,-12 264,-56 264,-56 264,-62 258,-68 252,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.998</text>\r\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 452</text>\r\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [214, 238]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.607,-103.726C195.137,-95.4263 195.697,-86.6671 196.233,-78.2834\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.726,-78.5025 196.871,-68.2996 192.74,-78.0559 199.726,-78.5025\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.552941\" stroke=\"black\" d=\"M400,-68C400,-68 308,-68 308,-68 302,-68 296,-62 296,-56 296,-56 296,-12 296,-12 296,-6 302,-0 308,-0 308,-0 400,-0 400,-0 406,-0 412,-6 412,-12 412,-12 412,-56 412,-56 412,-62 406,-68 400,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.892</text>\r\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 55</text>\r\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 38]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.393,-103.726C357.863,-95.4263 357.303,-86.6671 356.767,-78.2834\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"360.26,-78.0559 356.129,-68.2996 353.274,-78.5025 360.26,-78.0559\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.909804\" stroke=\"black\" d=\"M540,-68C540,-68 442,-68 442,-68 436,-68 430,-62 430,-56 430,-56 430,-12 430,-12 430,-6 436,-0 442,-0 442,-0 540,-0 540,-0 546,-0 552,-6 552,-12 552,-12 552,-56 552,-56 552,-62 546,-68 540,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"491\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.413</text>\r\n",
       "<text text-anchor=\"middle\" x=\"491\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 301</text>\r\n",
       "<text text-anchor=\"middle\" x=\"491\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 276]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"491\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = good</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.407,-103.726C420.56,-94.3318 432.412,-84.349 443.525,-74.9883\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.073,-77.4188 451.466,-68.2996 441.563,-72.065 446.073,-77.4188\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1f99bc5b2c8>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = export_graphviz(dt, out_file=None, \n",
    "    feature_names=one_hot_cols,  \n",
    "    class_names=list(reversed(credit_clean['Approve'].unique())),  \n",
    "    filled=True, rounded=True,  \n",
    "    special_characters=False)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to visualise the tree is to open the output .dot file with an editor such as [this online .dot renderer](http://dreampuf.github.io/GraphvizOnline/). You can use the code below to create a dot-file and then copy and paste its contents into the online site (you can double click on the tree once it has been produced to view it in full screen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tree.dot\", 'w') as f:\n",
    "    f = export_graphviz(dt, out_file=f,\n",
    "                        feature_names=one_hot_cols,  \n",
    "                        class_names=list(reversed(credit_clean['Approve'].unique())),  \n",
    "                        filled=True, rounded=True,  \n",
    "                        special_characters=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.13 ==========\n",
    "Inspect the tree and\n",
    " 1. describe what it shows, explaining how you interpret any one-hot encoded data\n",
    " 1. indicate which is the attribute with the highest information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***\n",
    "\n",
    "People in the dataset are split into 4 groups: \"Checking Account & Duration < One year\", \"Checking Account & Duration >= One year\", \"No Checking Account & Other Plans\", \"No Checking Account & No Other Plans\". But they're all classfied negatively, although for people with a checking account and a duration of at least a year, it's close. \n",
    "\n",
    "**The splits have the following information gains:**\n",
    "\n",
    "Checking Account: 0.085\n",
    "\n",
    "Duration: 0.031\n",
    "\n",
    "Other Plans: 0.022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.14 ==========\n",
    "Tree-based estimators (i.e. decision trees and random forests) can be used to compute feature importances. The importance of a feature is computed as the (normalized) total reduction of entropy (or other used `criterion`) brought by that feature. Find the relevant attributes of the classifier you just trained (i.e. those which are actually used in this short tree) and display feature importances along with their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckingAccount_none : 0.7176194261140465\n",
      "Duration : 0.16073405056934223\n",
      "OtherPlans_none : 0.12164652331661123\n"
     ]
    }
   ],
   "source": [
    "for key in [\"CheckingAccount_none\", \"Duration\", \"OtherPlans_none\"]:\n",
    "    print(key, \":\", dt.feature_importances_[one_hot_cols.get_loc(key)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.15 ==========\n",
    "Now we want to evaluate the performance of the classifier on unseen data. Use the trained model to predict the target variables for the test data set. Display the classification accuracy for both the training and test data sets. What do you observe? Are you surprised by the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t 0.6944444444444444\n",
      "Testing:\t 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\\t\", accuracy_score(dt.predict(X_train), y_train))\n",
    "print(\"Testing:\\t\", accuracy_score(dt.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimator just classfies everything as \"good\". So the result we got is just the baseline. We could have used a depth of 0 to achieve this, we have to do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STARTHIDE#\n",
    "\n",
    "The decision tree classifier is (probably) not overfitting. The classification accuracy is similar for training and test. The decision tree has provided a very simple way to interpret the data - splitting it into 8 bins and applying a class to each bin. Clearly this is an oversimplification: even in the training data, the leaves of the tree contain many examples of the 'incorrect' class.\n",
    "\n",
    "#ENDHIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, the very astute will make an observation:** *Hint: Have a look at the class distribution in the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,4))\n",
    "sns.countplot(y_train, ax=ax1)\n",
    "ax1.set_title('Training set', size=12)\n",
    "ax1.set_xlabel(' ')\n",
    "sns.countplot(y_test, ax=ax2)\n",
    "ax2.set_xlabel(' ')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Validation set', size=12)\n",
    "fig.suptitle('Target distribution', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier of predicting everything as 'good' **will beat this model (75% accuracy on Validation Set)!** In other words, our model is worse than the baseline. **Always compare your models with very simple baselines**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.16 ==========\n",
    "\n",
    "Fit another `DecisionTreeClassifier` but this time grow it to full depth (i.e. remove the max_depth condition). Again, use a `random_state=1000`. Display the classification accuracy for training and test data as above. Again, what do you observe and are you surprised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t 1.0\n",
      "Testing:\t 0.67\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "dt_deep = DecisionTreeClassifier(criterion=\"entropy\", random_state=1000)\n",
    "dt_deep.fit(X_train, y_train)\n",
    "print(\"Training:\\t\", accuracy_score(dt_deep.predict(X_train), y_train))\n",
    "print(\"Testing:\\t\", accuracy_score(dt_deep.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***\n",
    "\n",
    "Despite perfect accuracy on the training data (which is a given if there are no duplicates in the data), this classifier actually performs worse on the testing data than our naive baseline. I am not particularly surprised, because an unpruned decision tree classifier is bound to overfit the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.17 ==========\n",
    "By using seaborn's heatmap function, plot the normalised confusion matrices for both the training and test data sets **for the max_depth=3 decision tree from question 1.12**. Make sure you label axes appropriately. *Hint: You can make use of the `plot_confusion_matrix` function introduced in a previous lab, reproduced below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalised Data\n",
    "\n",
    "# Your Code goes here:\n",
    "classes = list(reversed(credit_clean['Approve'].unique()))\n",
    "\n",
    "training_totals = [len(y_train[y_train == label]) for label in classes]\n",
    "norm_mat_train = np.array(training_totals * 2).reshape(2,2).transpose()\n",
    "\n",
    "cm_train = np.divide(confusion_matrix(y_train, dt.predict(X_train)), norm_mat_train)\n",
    "plot_confusion_matrix(cm_train, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation Data\n",
    "\n",
    "# Your Code goes here:\n",
    "testing_totals = [len(y_test[y_test == label]) for label in classes]\n",
    "norm_mat_test = np.array(testing_totals * 2).reshape(2,2).transpose()\n",
    "\n",
    "cm_test = np.divide(confusion_matrix(y_test, dt.predict(X_test)), norm_mat_test)\n",
    "plot_confusion_matrix(cm_test, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B. it will be obvious if you have plotted the full depth decision tree as the training confusion matrix will be the identity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.18 ==========\n",
    "\n",
    "Finally we will create a [`Random decision forest`](http://scikit-learn.org/0.19/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier and compare the performance of this classifier to that of the decision tree. The random decision forest is an ensemble classifier that consists of many decision trees and outputs the class that is the mode of the class's output by individual trees. Start with `n_estimators = 100`, use the `entropy` criterion and the same train/test split as before. Plot the classification accuracy of the random forest model on the test set and show the confusion matrix. How does the random decision forest compare performance wise to the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t 1.0\n",
      "Testing:\t 0.74\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "gump = RandomForestClassifier(n_estimators=100, criterion=\"entropy\")\n",
    "gump.fit(X_train, y_train)\n",
    "print(\"Training:\\t\", accuracy_score(gump.predict(X_train), y_train))\n",
    "print(\"Testing:\\t\", accuracy_score(gump.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.19 ==========\n",
    "How high can you get the performance of the classifier by changing the max depth of the trees (`max_depth`), or the `max_features` parameters? Try a few values just to get a look. *Don't do a grid search or anything in-depth, just get a feel*. Try the same settings twice...do you get the same accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 3 Features: 3\n",
      "Training:\t 0.6944444444444444\n",
      "Testing:\t 0.75\n",
      "Depth: 3 Features: 5\n",
      "Training:\t 0.6955555555555556\n",
      "Testing:\t 0.75\n",
      "Depth: 3 Features: 7\n",
      "Training:\t 0.7033333333333334\n",
      "Testing:\t 0.75\n",
      "Depth: 3 Features: 10\n",
      "Training:\t 0.7255555555555555\n",
      "Testing:\t 0.75\n",
      "Depth: 5 Features: 3\n",
      "Training:\t 0.7144444444444444\n",
      "Testing:\t 0.75\n",
      "Depth: 5 Features: 5\n",
      "Training:\t 0.7377777777777778\n",
      "Testing:\t 0.75\n",
      "Depth: 5 Features: 7\n",
      "Training:\t 0.7733333333333333\n",
      "Testing:\t 0.74\n",
      "Depth: 5 Features: 10\n",
      "Training:\t 0.8\n",
      "Testing:\t 0.72\n",
      "Depth: 7 Features: 3\n",
      "Training:\t 0.7733333333333333\n",
      "Testing:\t 0.75\n",
      "Depth: 7 Features: 5\n",
      "Training:\t 0.8244444444444444\n",
      "Testing:\t 0.76\n",
      "Depth: 7 Features: 7\n",
      "Training:\t 0.8688888888888889\n",
      "Testing:\t 0.76\n",
      "Depth: 7 Features: 10\n",
      "Training:\t 0.8777777777777778\n",
      "Testing:\t 0.72\n",
      "Depth: 10 Features: 3\n",
      "Training:\t 0.9222222222222223\n",
      "Testing:\t 0.75\n",
      "Depth: 10 Features: 5\n",
      "Training:\t 0.95\n",
      "Testing:\t 0.72\n",
      "Depth: 10 Features: 7\n",
      "Training:\t 0.9522222222222222\n",
      "Testing:\t 0.74\n",
      "Depth: 10 Features: 10\n",
      "Training:\t 0.9644444444444444\n",
      "Testing:\t 0.73\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "for depth, feats in [(3,3), (3,5), (3, 7), (3,10), (5,3), (5,5), (5, 7), (5,10), \n",
    "                     (7,3), (7,5), (7, 7), (7,10), (10,3), (10,5), (10, 7), (10,10)]:\n",
    "    print(\"Depth:\", depth, \"Features:\", feats)\n",
    "    gump = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=depth, max_features=feats)\n",
    "    gump.fit(X_train, y_train)\n",
    "    print(\"Training:\\t\", accuracy_score(gump.predict(X_train), y_train))\n",
    "    print(\"Testing:\\t\", accuracy_score(gump.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. Observing these confusion matrices you'll see something very important - for some configurations, the Random Forest **always predicts the majority class**: incidentally these are also the cases which do the best. This highlights (again) the importance of always checking performance against a dummy classifier!!!\n",
    "\n",
    "Additionally, if you want to reproduce your results, you must set the random seed (you can do this with the `random_state` argument). Random forests are...random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.20 ==========\n",
    "Compare the feature importances as estimated with the decision tree and random forest classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08081885, -0.0903736 , -0.06972641, -0.04814714, -0.01852313,\n",
       "       -0.00560607,  0.64632518, -0.02366448, -0.01407516, -0.01152661,\n",
       "       -0.01032427, -0.00899271, -0.00142148, -0.00793641, -0.01849372,\n",
       "       -0.01489551, -0.00656277, -0.00891365, -0.00235955, -0.00374366,\n",
       "       -0.00109626, -0.01204155, -0.02061601, -0.00653559, -0.00555099,\n",
       "       -0.0063673 , -0.01472349, -0.01360042, -0.0115993 , -0.01006974,\n",
       "       -0.01153553, -0.00586749, -0.00843684, -0.00962374, -0.00904713,\n",
       "       -0.01460417, -0.01124276, -0.00493743, -0.00694859, -0.01129415,\n",
       "       -0.0059935 , -0.00802744, -0.00846602, -0.00738265, -0.01183583,\n",
       "       -0.00912358, -0.01309981, -0.0106285 , -0.01411386, -0.01083792,\n",
       "       -0.01294344, -0.01382597,  0.10670594, -0.0060424 , -0.00748996,\n",
       "       -0.01497983, -0.01174647, -0.01066449, -0.01094232, -0.0025737 ,\n",
       "       -0.00098291, -0.01150526, -0.01115065, -0.00217624, -0.01085675,\n",
       "       -0.00846606, -0.00886399, -0.01087484, -0.01089649, -0.00307945,\n",
       "       -0.00325483])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.feature_importances_ - gump.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Duration\n",
      "6: CheckingAccount_none\n"
     ]
    }
   ],
   "source": [
    "print(\"0:\", one_hot_cols[0])\n",
    "print(\"6:\", one_hot_cols[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all features are slightly more important for the forest, except for 2:\n",
    "The importance of Duration was apparently overestimated by our initial Tree model. \n",
    "But especially whether a person has a checking account was WAY more important to our Tree than it is to our Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear regression\n",
    "In the second part of the lab we use the [CPU performance](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware) dataset for a simple regression task. Famliarise yourself with the dataset before moving on to the next step. Note that the version we will be using is missing the `Model Name` and `PRP` attributes. Our task will be to use the remaining attributes to predict `ERP` values.\n",
    "\n",
    "Download the dataset and save it in a directory called `datasets` in the same folder that your notebooks live. Alternatively, you can save the dataset in any folder you wish and modify the `data_path` variable below accordingly. We will load our data into a pandas DataFrame structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'cpu.csv')\n",
    "cpu = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "Display the number of data points and attributes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ==========\n",
    "Get a feeling of the data by using pandas `describe()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Display the first 10 data points of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ========== \n",
    "You might have noticed that the `vendor` attribute is categorical. This will give problems when using a linear regression model. For now we can simply remove this attribute. Create a new DataFrame called `cpu_clean` by copying `cpu` but omit the `vendor` attribute. Display the number of samples and attributes in the clean dataset as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 ==========\n",
    "Now -as always- we want to perform some exploratory data analysis. Remember that our task is to predict `ERP` values, so it's a good idea to inspect individual scatter plots of the target variable (`ERP`) against our input features. For this purpose we will use once again seaborn's pairplot implementation.\n",
    "\n",
    "Create a series of [pairplots](https://seaborn.github.io/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) showing the pairwise relationship of `ERP` and the remaining attributes in the data. You can do so by specifying explicitly the `x_vars` and `y_vars` input arguments in the pairplot. *Hnt: Your final plot will consist of 6 subplots each contaning a scatter plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "* Do you think that ERP should be at least partially predictable from the input attributes?\n",
    "* Do any attributes exhibit significant correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Now we have a feel for the data and we will try fitting a simple linear regression model. Similarly to what we did in the first part of the lab, we want to use cross-validation to evaluate the goodness of the fit.\n",
    "\n",
    "By using the `cpu_clean` dataset extract the raw values for the input features and the target variable and store them in two matrices, called `X` and `y` respectively. \n",
    "\n",
    "Then, split the dataset into training and testing sets by using a 75%-25% split (training/testing).\n",
    "\n",
    "Display the shapes of all matrices involved and double-check that all dimensionalities appear to be as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "Fit a simple linear regressor by using the [`LinearRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LinearRegression.html) model in Scikit-learn. Report the training accuracy by using the `score` attribute. What does this represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "Now report the testing accuracy by using the `score` attribute of the regressor as well as the `r2_score` metric. Confirm that these two yield identical results.\n",
    "\n",
    "How does the accuracy compare to the one reported on the training dataset? Do you think that your model does well on generalising on unseen data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "Now we want to get a feel for how good the fit is, so we wil plot the measured values against the predicted ones. Make use of the function provided below which takes as input arguments the measured (`y_true`) and predicted (`y_pred`) values of a target variable and produces a scatter plot for the two by also including a straight line going through the origin. \n",
    "\n",
    "Where would you expect the points to be for a perfect fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_scatter(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "Another way of assessing the performance of the model is to inspect the distribution of the errors. Make a histogram plot by using seaborn's `displot` function. This will also show an estimate of the underlying distribution.\n",
    "\n",
    "Does it look like the errors are normally distributed? Would you trust the fit of the distribution on the graph? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "Above we deleted the vendor variable. However, we can use nominal attributes in regression by converting them to numeric, exactly in the same way that we did at the first part of this lab. \n",
    "\n",
    "Now, use the original `cpu` dataset and convert the `vendor` attribute to a numeric one by means of one-hot-encoding. Then train a linear regression model to the data and compare its performance to the one we had previously. Did adding the *binazired vendor* variable help? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
