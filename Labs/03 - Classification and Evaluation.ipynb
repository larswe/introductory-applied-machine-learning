{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Support Vector Machine (SVM) Classification and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we initially re-examine the spam filtering problem from Lab 2. This time, we train a Logistic Regression model and a linear Support Vector Machine for the spam or non-spam classification task. In the second part of the lab we examine classification evaluation by using a K-nearest neighbour classifier.\n",
    "\n",
    "\n",
    "All the datasets that you will need for this lab are located within the `datasets` directory (adjacent to this file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsw\\anaconda3\\envs\\py3iaml\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from pandas.api.types import CategoricalDtype\n",
    "KNeighboursClassifier = KNeighborsClassifier # For the Brits!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Load `spambase_binary.csv` into a pandas DataFrame structure called `spambase`. Display the number of instances and attributes and the first 5 samples. Remember that the attributes have been binarised. The instances have also been shuffled (i.e. their order has been randomised). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 4601\n",
      "Attributes: 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make_binarized</th>\n",
       "      <th>word_freq_address_binarized</th>\n",
       "      <th>word_freq_all_binarized</th>\n",
       "      <th>word_freq_3d_binarized</th>\n",
       "      <th>word_freq_our_binarized</th>\n",
       "      <th>word_freq_over_binarized</th>\n",
       "      <th>word_freq_remove_binarized</th>\n",
       "      <th>word_freq_internet_binarized</th>\n",
       "      <th>word_freq_order_binarized</th>\n",
       "      <th>word_freq_mail_binarized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu_binarized</th>\n",
       "      <th>word_freq_table_binarized</th>\n",
       "      <th>word_freq_conference_binarized</th>\n",
       "      <th>char_freq_;_binarized</th>\n",
       "      <th>char_freq_(_binarized</th>\n",
       "      <th>char_freq_[_binarized</th>\n",
       "      <th>char_freq_!_binarized</th>\n",
       "      <th>char_freq_$_binarized</th>\n",
       "      <th>char_freq_#_binarized</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make_binarized  word_freq_address_binarized  \\\n",
       "0                         0                            1   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   word_freq_all_binarized  word_freq_3d_binarized  word_freq_our_binarized  \\\n",
       "0                        0                       0                        1   \n",
       "1                        0                       0                        0   \n",
       "2                        1                       0                        0   \n",
       "3                        1                       0                        1   \n",
       "4                        0                       0                        1   \n",
       "\n",
       "   word_freq_over_binarized  word_freq_remove_binarized  \\\n",
       "0                         0                           1   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   word_freq_internet_binarized  word_freq_order_binarized  \\\n",
       "0                             1                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          1   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   word_freq_mail_binarized   ...     word_freq_edu_binarized  \\\n",
       "0                         1   ...                           0   \n",
       "1                         0   ...                           1   \n",
       "2                         0   ...                           0   \n",
       "3                         0   ...                           0   \n",
       "4                         0   ...                           0   \n",
       "\n",
       "   word_freq_table_binarized  word_freq_conference_binarized  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   char_freq_;_binarized  char_freq_(_binarized  char_freq_[_binarized  \\\n",
       "0                      0                      1                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   char_freq_!_binarized  char_freq_$_binarized  char_freq_#_binarized  \\\n",
       "0                      1                      1                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      1                      0                      0   \n",
       "4                      1                      1                      0   \n",
       "\n",
       "   is_spam  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase_binary.csv')\n",
    "spam_bin = pd.read_csv(data_path, delimiter = ',')\n",
    "print(\"Instances:\", len(spam_bin))\n",
    "print(\"Attributes:\", len(spam_bin.columns))\n",
    "spam_bin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "We are going to use hold-out validation to evaluate our models below. Split the dataset into training and testing subsets using the `train_test_split` [function](http://scikit-learn.org/0.19/modules/generated/sklearn.cross_validation.train_test_split.html) we have used before. Call the resulting matrices `X_train`, `X_test`, `y_train`, `y_test`. Use 90% of the data for training and the remaining 10% for testing. Make sure you don't include the target variable `is_spam` in the input features (`X_train` / `X_test`)!\n",
    "\n",
    "If you want to be able to reproduce your results exactly, what argument must you remember to set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_bin.drop(columns=[\"is_spam\"])\n",
    "y = spam_bin[\"is_spam\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the random_state argument to an arbitrary number will make our results reproducable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "Train a [`LogisticRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier by using training data. Use the `lbfgs` solver and default settings for the other parameters. Report the classification accuracy on both the training and test sets. Does your classifier generalise well on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t 0.9335748792270532\n",
      "Testing accuracy:\t 0.9392624728850325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Training accuracy:\\t\", accuracy_score(y_train, log_reg.predict(X_train)))\n",
    "print(\"Testing accuracy:\\t\", accuracy_score(y_test, log_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the testing data is actually slightly better than on the training data. Our classifier appears to generalise amazingly to unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "Print the coefficients for class 1 for the attributes `word_freq_hp_binarized` and `char_freq_$_binarized`. Generally, we would expect the string `$` to appear in spam, and the string `hp` to appear in non-spam e-mails, as the data was collected from HP Labs. Do the regression coefficients make sense given that class 1 is spam? *Hint: Consider the sigmoid function and how it transforms values into a probability between 0 and 1. Since our attributes are boolean, a positive coefficient can only increase the total sum fed through the sigmoid and thus move the output of the sigmoid towards 1. What can happen if we have continuous, real-valued attributes?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp:\t -2.668005196393516\n",
      "$:\t 1.8282658790687296\n"
     ]
    }
   ],
   "source": [
    "print(\"hp:\\t\", log_reg.coef_[0][np.where(spam_bin.columns == \"word_freq_hp_binarized\")][0])\n",
    "print(\"$:\\t\", log_reg.coef_[0][np.where(spam_bin.columns == \"char_freq_$_binarized\")][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our attributes can only take values 0 or 1. Thus, a word can only ever affect the output of the dot product of instance and weight vectors, and thus of the sigmoid function, if it takes value 1, i.e. is present. An attribute with negative weight will decrease the output if it appears, an attribute with positive weight will increase it. Because a large output (close to 1) corresponds to a spammy e-mail, we expect \"$\" to have a positive weight and \"hp\" to have a negative weight. And indeed, that is the case. \n",
    "\n",
    "If attribute values can be negative, a positive weight will decrease our output given a negative attribute value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "Train a [`LinearSVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (i.e. Linear Support Vector classifier) by using default parameters. Report the classification accuracy on the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t 0.9326086956521739\n",
      "Testing accuracy:\t 0.9370932754880694\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "print(\"Training accuracy:\\t\", accuracy_score(y_train, svc.predict(X_train)))\n",
    "print(\"Testing accuracy:\\t\", accuracy_score(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "What are the coefficients for the attributes `word_freq_hp_binarized` and `char_freq_`$`_binarized`? Compare these to the ones you found with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp:\t -0.877242685392654\n",
      "$:\t 0.6065817684041339\n"
     ]
    }
   ],
   "source": [
    "print(\"hp:\\t\", svc.coef_[0][np.where(spam_bin.columns == \"word_freq_hp_binarized\")][0])\n",
    "print(\"$:\\t\", svc.coef_[0][np.where(spam_bin.columns == \"char_freq_$_binarized\")][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the weight corresponding to \"hp\" is negative, the weight corresponding to \"$\" positive. However, both values are more restricted, i.e. closer to 0. Their ratio is about the same as in the Log. Reg. model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "How does a linear SVM relate to Logistic Regression? *Hint: Consider the classification boundary learnt in each model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the decision boundaries that a linear SVM and a Logistic Regression model produce to be very similar.\n",
    "Afterall, they are both linear. Because Logistic Regression models involve confidence, the weights of the hyperplane may be scaled differently, however the shape of the two boundary in the 2 models should be roughly the same.\n",
    "A larger scale in a Log. Reg. model corresponds to a larger confidence, relevant especially near the decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "By using the [`SVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) class train two new support vector classifiers with Gaussian (`rbf`) and polynomial (`poly`) kernels. Again, report classification accuracies on training and test sets and compare with your results from Question 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy Gaussian:\t 0.9350241545893719\n",
      "Testing accuracy Gaussian:\t 0.9370932754880694\n",
      "Training accuracy Poly:\t 0.798792270531401\n",
      "Testing accuracy Poly:\t 0.8199566160520607\n"
     ]
    }
   ],
   "source": [
    "svc_gauss = SVC(kernel=\"rbf\")\n",
    "svc_gauss.fit(X_train, y_train)\n",
    "print(\"Training accuracy Gaussian:\\t\", accuracy_score(y_train, svc_gauss.predict(X_train)))\n",
    "print(\"Testing accuracy Gaussian:\\t\", accuracy_score(y_test, svc_gauss.predict(X_test)))\n",
    "svc_poly = SVC(kernel=\"poly\")\n",
    "svc_poly.fit(X_train, y_train)\n",
    "print(\"Training accuracy Poly:\\t\", accuracy_score(y_train, svc_poly.predict(X_train)))\n",
    "print(\"Testing accuracy Poly:\\t\", accuracy_score(y_test, svc_poly.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Gaussian SVC is very similar on the training and absolutely identical to the linear SVC on the testing data.\n",
    "Interestingly, the SVC with polynomial kernel performs much worse on both sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance assessment\n",
    "We will now look at a few ways of assessing the performance of a classifier. To do so we will introduce a new data set, the [Splice](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) data set. The classification task is to identify `intron` and `exon` boundaries on gene sequences. For more information, you can read the dataset description in the link. The class attribute can take on 3 values: `N`, `IE` and `EI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "Load the `splice_train.csv` and `splice_test.csv` into two separate dataframes. Display the shape and first 10 instances for each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 2935\n",
      "Attributes: 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    T    G    A    T    G    C    C    T    G    C  ...      C     C     C   \n",
       "1    G    C    C    C    A    T    A    T    T    C  ...      T     G     G   \n",
       "2    G    G    C    T    G    C    C    G    G    A  ...      A     C     T   \n",
       "3    C    T    G    C    T    G    C    T    G    G  ...      G     G     C   \n",
       "4    T    C    C    C    C    G    A    G    C    C  ...      A     T     C   \n",
       "5    A    T    A    C    C    T    G    C    C    C  ...      A     T     G   \n",
       "6    T    T    C    T    C    C    A    T    T    T  ...      G     A     T   \n",
       "7    A    A    A    G    A    T    G    A    T    A  ...      A     A     G   \n",
       "8    C    C    A    A    T    C    C    C    A    G  ...      G     G     C   \n",
       "9    G    C    C    G    T    G    G    T    T    T  ...      A     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     C     C     T     G     A     G     N  \n",
       "1     A     C     T     T     C     C     N  \n",
       "2     G     T     G     T     C     T    EI  \n",
       "3     T     G     C     T     G     G    EI  \n",
       "4     A     G     C     G     C     A     N  \n",
       "5     G     G     G     T     C     T    EI  \n",
       "6     A     T     C     C     A     T    IE  \n",
       "7     C     C     C     T     T     C    EI  \n",
       "8     G     G     C     C     T     G     N  \n",
       "9     G     C     T     C     C     T    EI  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'datasets', 'splice_train.csv')\n",
    "splice_train = pd.read_csv(data_path, delimiter = ',')\n",
    "print(\"Instances:\", len(splice_train))\n",
    "print(\"Attributes:\", len(splice_train.columns))\n",
    "splice_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 255\n",
      "Attributes: 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    C    C    C    T    C    C    C    A    C    T  ...      C     C     C   \n",
       "1    C    A    C    T    G    A    G    T    T    G  ...      G     A     A   \n",
       "2    C    A    G    A    C    T    G    G    G    T  ...      A     G     A   \n",
       "3    A    G    T    G    A    T    T    G    A    C  ...      T     A     C   \n",
       "4    G    T    A    G    A    C    A    C    C    T  ...      A     T     C   \n",
       "5    C    T    T    G    T    T    A    C    A    G  ...      C     C     G   \n",
       "6    C    G    T    C    A    A    T    C    A    A  ...      A     A     A   \n",
       "7    G    T    C    C    G    T    G    C    C    T  ...      G     C     C   \n",
       "8    A    T    A    C    C    T    G    T    A    G  ...      C     G     T   \n",
       "9    G    G    T    G    G    G    C    C    A    A  ...      C     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     A     G     T     G     C     A    IE  \n",
       "1     C     C     A     G     T     G     N  \n",
       "2     C     C     A     C     A     G    EI  \n",
       "3     C     A     A     A     G     A     N  \n",
       "4     C     C     T     T     C     T    IE  \n",
       "5     A     G     A     A     C     C     N  \n",
       "6     A     T     T     A     A     G    EI  \n",
       "7     C     T     T     T     G     C     N  \n",
       "8     T     T     A     T     A     T     N  \n",
       "9     G     C     A     T     G     G     N  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'datasets', 'splice_test.csv')\n",
    "splice_test = pd.read_csv(data_path, delimiter = ',')\n",
    "print(\"Instances:\", len(splice_test))\n",
    "print(\"Attributes:\", len(splice_test.columns))\n",
    "splice_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ========== \n",
    "Convert the categorical attributes into numeric ones by using the [`get_dummies(...)`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.get_dummies.html) function from pandas. Make sure to take care of the values `D`, `N`, `S`, `R` (see the [documentation](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) for the data). *Hint: checkout the pandas [`CategoricalDtype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.api.types.CategoricalDtype.html#pandas.api.types.CategoricalDtype)*. Also, make sure to not transform the target variable (`class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_categories = list(\"AGCTDNSR\")\n",
    "\n",
    "train_dummies = pd.get_dummies(splice_train.drop(columns=\"class\").astype\n",
    "                               (CategoricalDtype(categories=possible_categories)))\n",
    "test_dummies = pd.get_dummies(splice_test.drop(columns=\"class\").astype\n",
    "                               (CategoricalDtype(categories=possible_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Store the training and testing data into numpy arrays `X_train`, `y_train`, `X_test` and `y_test`. Display the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train:\t (2935, 480)\n",
      "Shape y_train:\t (2935,)\n",
      "Shape X_test:\t (255, 480)\n",
      "Shape y_test:\t (255,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_dummies\n",
    "X_test = test_dummies\n",
    "y_train = splice_train[\"class\"]\n",
    "y_test = splice_test[\"class\"]\n",
    "print(\"Shape X_train:\\t\", X_train.shape)\n",
    "print(\"Shape y_train:\\t\", y_train.shape)\n",
    "print(\"Shape X_test:\\t\", X_test.shape)\n",
    "print(\"Shape y_test:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ==========\n",
    "Familiarise yourself with [Nearest Neighbours Classification](http://scikit-learn.org/0.19/modules/neighbors.html#classification). Use a [`KNeighborsClassifier`](http://scikit-learn.org/0.19/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "by using a single neighbour. Report the classification accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t 0.9996592844974447\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighboursClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Training accuracy:\\t\", accuracy_score(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 ==========\n",
    "Is the above result meaningful? Why is testing on the training data a particularly bad idea for a 1-nearest neighbour classifier? Do you expect the performance of the classifier on a test set to be as good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result is absolutely meaningless. The nearest neighbour of any training instance is of course the training instance itself. So unless we have duplicates in our data, we expect a training accuracy of 100%, no matter how useful (or useless) the classifier actually is. \n",
    "\n",
    "It's probably gonna perform rather poorly on the test set, since using a single nearest neighbour is extremely sensitive to outliers and not a great technique in general. (unless our data is EXTREMELY well-behaved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "Now report the classification accuracy on the test set and check your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\t 0.7490196078431373\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy:\\t\", accuracy_score(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Plot a histogram of the target variable (i.e. `class`) in the test set. *Hint: matplotlib won't allow you to plot a histogram for categorical values. Instead, you can use Pandas' built-in bar plot tool in conjunction with the [`value_counts`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.value_counts.html).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16c6c4151c8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = y_test.value_counts()\n",
    "counts.plot.bar(title=\"Class value counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "What would be the accuracy of the classifier, if all points were labelled as `N`? \n",
    "\n",
    "**Pro Tip** - You should always use a ['Dummy Model'](http://scikit-learn.org/0.19/modules/model_evaluation.html#dummy-estimators) (a ridiculously simple model) like this to compare with your 'real' models. It's very common for complex models to be outperformed by a simple model, such as predicting the most common class. When complex models are outperformed by 'Dummies', you should investigate why: often there was an issue with the code, the data, or the way the model works was misunderstood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5843137254901961"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, [\"N\" for y in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "Now we want to explore the effect of the `k` parameter. To do this, train the classifier multiple times, each time setting the KNN option to a different value. Try `5`, `10`, `50`, `100`, `200`, `500`, `1000`, `1500` and `2000` and test the classifier on the test set. How does the k parameter effect the results? *Hint: Consider how well the classifier is generalising to previously unseen data, and how it compares to the dumb prediction accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for k = 5 :\t 0.7803921568627451\n",
      "Testing accuracy for k = 10 :\t 0.8274509803921568\n",
      "Testing accuracy for k = 50 :\t 0.8705882352941177\n",
      "Testing accuracy for k = 100 :\t 0.8980392156862745\n",
      "Testing accuracy for k = 200 :\t 0.8980392156862745\n",
      "Testing accuracy for k = 500 :\t 0.9450980392156862\n",
      "Testing accuracy for k = 1000 :\t 0.9568627450980393\n",
      "Testing accuracy for k = 1500 :\t 0.6980392156862745\n",
      "Testing accuracy for k = 2000 :\t 0.5843137254901961\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "ks = [5, 10, 50, 100, 200, 500, 1000, 1500, 2000]\n",
    "\n",
    "for k in ks:\n",
    "    knn = KNeighboursClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, knn.predict(X_test))\n",
    "    accuracies.append(acc)\n",
    "    print(\"Testing accuracy for k =\", k, \":\\t\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low values of k, the algorithm does not do too well on unseen data. The decision boundaries seem to be too unstable, too strongly affected by outliers. \n",
    "At k in the range 500-1000 we seem to hit the sweet spot. But as we further increase k, our classifier tends to simply output the most common class. \n",
    "At k=2000 that appears to be what our classifier ALWAYS does, as its accuracy matches the accuracy of our dummy model exactly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "Plot the results (k-value on the x-axis and classification accuracy on the y-axis), making sure to mark the axes. Can you conclude anything from observing the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ks, accuracies)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy hits a plateau after k=500, increasing very fast in the range (0, 100) and decreasing very fast after k=1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "Select best value for `k` from Questions 2.9 and 2.10 and plot the normalised confusion matrix on the test set (you may use the provided function). Then plot the confusion matrix for a 5-nearest neighbour classifier. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_knn = KNeighboursClassifier(n_neighbors = 1000)\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "simple_knn = KNeighboursClassifier(n_neighbors = 5)\n",
    "simple_knn.fit(X_train, y_train)\n",
    "\n",
    "classes = y_test.value_counts().index\n",
    "test_totals = [len(y_test[y_test == label]) for label in classes]\n",
    "norm_mat_test = np.array(test_totals * 3).reshape(3,3).transpose()\n",
    "\n",
    "best_cm = confusion_matrix(y_test, best_knn.predict(X_test), labels=classes)\n",
    "best_cm = np.divide(best_cm, norm_mat_test)\n",
    "plot_confusion_matrix(best_cm, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_cm = confusion_matrix(y_test, simple_knn.predict(X_test), labels=classes)\n",
    "simple_cm = np.divide(simple_cm, norm_mat_test)\n",
    "plot_confusion_matrix(simple_cm, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier with k=1000 has perfect accuracy on instances of the most common class. Intuitively this makes sense, because a large k should make the most common classes selected more often. \n",
    "\n",
    "The confusion matrix for k=5, on the other hand, shows that the simple classifier performs way worse on instances of the most common class, but actually has close to perfect accuracy on instances of the EI class. Presumably, this corresponds to N instances in the outskirts of the region primarily associated with class N being falsely associated with the more densely sprinkled instances of classes IE and especially EI in their proximity. \n",
    "\n",
    "When k is large, the converse occurs. The instances in the outskirts of the N region may not be dense, but since the class is so common and N so large, they sometimes lead to members of the EI class to be associated with members of EI that don't lie in the centre of the according region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "Read about the [logarithimic loss](http://scikit-learn.org/0.19/modules/generated/sklearn.metrics.log_loss.html) (or cross-entropy loss). It is often the error metric used when we are trying to optimise classification models.\n",
    "\n",
    "This metric takes as input the true labels and the estimated probability distributions (bernouli or multinomial). It makes sense to use this metric when we are interested not only in the predicted labels, but also in the confidence with which these labels are predicted.\n",
    "\n",
    "For instance, think of the situation where you have a single test point and two classifiers. Both classifiers predict the label correctly, however classifier A predicts that the test point belongs to the class with probability 0.55, whereas classifier B predicts the correct class with probability 0.99. Classification accuracy would be the same for the two classifiers (why?) but the `log_loss` metric would indicate that classifier B should be favoured.\n",
    "\n",
    "Produce a scatter plot similar to the one in Question 2.10 but this time show `log_loss` on your y axis. Which value for `k` would you pick if `log_loss` was the error metric? Comment on why this might happen, and which metric would be a better evaluator of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing log loss for k = 5 :\t 1.2279286161956937\n",
      "Testing log loss for k = 10 :\t 0.49015613095797766\n",
      "Testing log loss for k = 50 :\t 0.526997604112542\n",
      "Testing log loss for k = 100 :\t 0.5569746046973265\n",
      "Testing log loss for k = 200 :\t 0.6008637135906136\n",
      "Testing log loss for k = 500 :\t 0.6703631188217446\n",
      "Testing log loss for k = 1000 :\t 0.7547572553452911\n",
      "Testing log loss for k = 1500 :\t 0.8177287055931994\n",
      "Testing log loss for k = 2000 :\t 0.8753647883393483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for k in ks:\n",
    "    knn = KNeighboursClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    loss = log_loss(y_test, knn.predict_proba(X_test))\n",
    "    losses.append(loss)\n",
    "    print(\"Testing log loss for k =\", k, \":\\t\", loss)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ks, losses)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_xlim([-10, 2010])\n",
    "ax.set_ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k=5 the log loss is largest. This corresponds to even 1 out of 5 nearest neighbors belonging to another class causing our classifier to be quite uncertain of its output. \n",
    "\n",
    "The log loss drops rapidly for k=10, as the algorithm becomes more stable. Outliers are, by definition, not densely packed, therefore we don't usually have more than one of them in a small area. This explains the low log loss value for k=10, actually the lowest for all k. \n",
    "\n",
    "As k grows further, so does the log loss. That is because the sets of nearest neighbours starts being less pure on average, as larger surroundings are considered. We would expect each set of nearest neighbours to contain a mixture of classes for larger k. \n",
    "\n",
    "For k=2000, k is close to our number of instances. The uncertainty of the model still isn't as high as for the k=5 model, but for a k this large, all the sets of nearest neighbours look quite similar each other, and are all quite polluted. They have to contain members of all classes, because k is larger than the number of instances in any single class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 ==========\n",
    "\n",
    "Could you use the `log_loss` metric to evaluate the performance of an SVM classifier? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because SVM classifiers do not have any confidence measure. Their ouput is simply a -1 or 1, depending on which side of the learned hyperplane an instance lies on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
